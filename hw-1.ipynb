{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymystem3.mystem import Mystem\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "from string import punctuation, digits\n",
    "punctuation = set(punctuation + '«»—–…“”\\n\\t' + digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### пройдитесь по всем папкам коллекции и соберите все пути .txt файлов\n",
    "\n",
    "main_dir = '/media/zu_ann/OS/Users/zu_ann/Yandex.Disk/HSE/IR/Friends'\n",
    "files_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for dr in dirs:\n",
    "        files_list += [main_dir + '/' + dr + '/' + file for file in os.listdir(main_dir + '/' + dr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### _check : в коллекции должно быть 165 файлов\n",
    "\n",
    "len(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_words(text):\n",
    "    m = Mystem()\n",
    "    table = str.maketrans({ch: ' ' for ch in punctuation})\n",
    "    \n",
    "    tokenized = word_tokenize(text.replace('\\ufeff', '').lower().translate(table))\n",
    "    \n",
    "    return [m.lemmatize(word)[0] for word in tokenized], len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_files(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        words_list, text_length = preprocess_words(f.read())\n",
    "        document_length[files_list.index(file)] = text_length\n",
    "        \n",
    "        return words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inverted_index(files_list) -> dict:\n",
    "    \"\"\"\n",
    "    Create inverted index by input doc collection and count the length of each document \n",
    "    :return: inverted index\n",
    "    \"\"\"\n",
    "    inverted_index = defaultdict(list)\n",
    "    global document_length\n",
    "    document_length = [None] * len(files_list)\n",
    "\n",
    "    for file in files_list:\n",
    "        for word in preprocess_files(file):\n",
    "            inverted_index[word].append(files_list.index(file))\n",
    "    \n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = get_inverted_index(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(input_text, operations):\n",
    "    stack = []\n",
    "    output = []\n",
    "    table = str.maketrans({'(': '( ', ')': ' )'})\n",
    "\n",
    "    query = input_text.lower().translate(table).split()\n",
    "\n",
    "    for elem in query:\n",
    "        \n",
    "        if elem == '(':\n",
    "            stack.append(elem)\n",
    "        \n",
    "        elif elem in operations:\n",
    "            if len(stack) > 0 and stack[-1] != '(':\n",
    "                output.append(stack[-1])\n",
    "                stack[-1] = elem\n",
    "            else:\n",
    "                stack.append(elem)\n",
    "        \n",
    "        elif elem == ')':\n",
    "            if stack[-1] == '(':\n",
    "                continue\n",
    "            else:\n",
    "                k = stack[-1]\n",
    "                while k != '(':\n",
    "                    output.append(stack.pop(-1))\n",
    "                    k = stack[-1]\n",
    "                stack.pop(-1)\n",
    "    \n",
    "        else:\n",
    "            output.append(elem)\n",
    "\n",
    "    if len(stack) == 1:\n",
    "        output = output + stack\n",
    "    elif len(stack) > 1:\n",
    "        output = output + stack[::-1]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### напишите функцию булева поиска по построенной матрице\n",
    "\n",
    "def boolean_search(input_text, inverted_index, collection_size):\n",
    "    \"\"\"\n",
    "    Produces a Boolean search according with the inverted index\n",
    "    :return: list of first 5 relevant documents\n",
    "    \"\"\"\n",
    "    relevant_documents = []\n",
    "    operations = ['&', 'или', 'не']\n",
    "    query = preprocess_query(input_text, operations)\n",
    "    \n",
    "    for i, elem in enumerate(query):\n",
    "        if elem not in operations:\n",
    "            relevant_documents.append(elem)\n",
    "    \n",
    "        elif elem == 'не':\n",
    "            a = relevant_documents.pop()\n",
    "            if type(a) != set:\n",
    "                a = set(inverted_index[a])\n",
    "            relevant_documents.append(set(range(collection_size)) - a)\n",
    "    \n",
    "        else:\n",
    "            a = relevant_documents.pop()\n",
    "            if type(a) != set:\n",
    "                a = set(inverted_index[a])\n",
    "        \n",
    "            b = relevant_documents.pop()\n",
    "            if type(b) != set:\n",
    "                b = set(inverted_index[b])\n",
    "\n",
    "        if elem == '&':\n",
    "                relevant_documents.append(a & b)\n",
    "        elif elem == 'или':\n",
    "            relevant_documents.append(a | b)\n",
    "    \n",
    "    return relevant_documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [\n",
    "    'Моника & Фиби & Рэйчел & Чендлер & Джоуи & Росс',\n",
    "    '(Моника ИЛИ Фиби) & Рэйчел & (Чендлер ИЛИ Джоуи) & Росс', \n",
    "    '(НЕ Моника) & Фиби & Рэйчел & Чендлер & Джоуи & (НЕ Росс)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{6, 136, 137, 10, 138, 13, 14, 142, 144, 145, 146, 147, 148, 149, 154, 27, 156, 160, 162, 163, 164, 51, 68, 113, 117, 119, 122, 123, 125}]\n"
     ]
    }
   ],
   "source": [
    "print(boolean_search(input_text[0], inverted_index, len(files_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0, 1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 142, 144, 145, 146, 147, 148, 21, 22, 149, 150, 154, 27, 155, 29, 156, 160, 162, 134, 163, 164, 39, 136, 137, 51, 54, 138, 68, 70, 112, 113, 114, 115, 117, 119, 120, 122, 123, 125}]\n"
     ]
    }
   ],
   "source": [
    "print(boolean_search(input_text[1], inverted_index, len(files_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[set()]\n"
     ]
    }
   ],
   "source": [
    "print(boolean_search(input_text[2], inverted_index, len(files_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью обратного индекса произведите следующую аналитику:  \n",
    "\n",
    "1) общая аналитика\n",
    "- какое слово является самым частотным?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "я 18530\n"
     ]
    }
   ],
   "source": [
    "for word in sorted(inverted_index, key=lambda x: len(inverted_index[x]), reverse=True)[:1]:\n",
    "    print(word, len(inverted_index[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- какое самым редким?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "реалистичный 1\n"
     ]
    }
   ],
   "source": [
    "for word in sorted(inverted_index, key=lambda x: len(inverted_index[x]), reverse=False)[:1]:\n",
    "    print(word, len(inverted_index[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- какой набор слов есть во всех документах коллекции?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если\n",
      "не\n",
      "что\n",
      "мы\n",
      "быть\n",
      "он\n",
      "а\n",
      "то\n",
      "и\n",
      "так\n",
      "на\n",
      "как\n",
      "в\n",
      "но\n",
      "у\n",
      "ты\n",
      "этот\n",
      "такой\n",
      "просто\n",
      "да\n",
      "ну\n",
      "сказать\n",
      "еще\n",
      "о\n",
      "знать\n",
      "это\n",
      "она\n",
      "думать\n",
      "они\n",
      "нет\n",
      "все\n",
      "хорошо\n",
      "хотеть\n",
      "мой\n",
      "я\n",
      "с\n"
     ]
    }
   ],
   "source": [
    "for word in inverted_index:\n",
    "    if set(range(165)) == set(inverted_index[word]):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) частота встречаемости имен главных героев в каждом сезоне      \n",
    "- какой сезон был самым популярным у Чендлера? у Моники?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_popular_season(inverted_index, name):\n",
    "    seasons = [[i for i in range(20)] + [0], \n",
    "               [i for i in range(20, 45)] + [0], \n",
    "               [i for i in range(45, 66)] + [0], \n",
    "               [i for i in range(66, 92)] + [0],\n",
    "               [i for i in range(92, 116)] + [0],\n",
    "               [i for i in range(116, 141)] + [0],\n",
    "               [i for i in range(141, 165)] + [0]]\n",
    "    \n",
    "    for ind in inverted_index[name]:\n",
    "        for i, season in enumerate(seasons):\n",
    "            if ind in season:\n",
    "                seasons[i][-1] += 1\n",
    "    \n",
    "    max_times = [0, 0]\n",
    "    for i, season in enumerate(seasons):\n",
    "        if season[-1] > max_times[1]:\n",
    "            max_times[0] = i + 1\n",
    "            max_times[1] = season[-1]\n",
    "    \n",
    "    return max_times[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_popular_season(inverted_index, 'чендлер')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_popular_season(inverted_index, 'моника')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- кто из главных героев статистически самый популярный? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "чендлер 724\n",
      "джоуи 682\n",
      "моника 684\n",
      "фиби 575\n",
      "росс 1016\n",
      "рэйчел 237\n"
     ]
    }
   ],
   "source": [
    "persons = ['чендлер', 'джоуи', 'моника', 'фиби', 'росс', 'рэйчел']\n",
    "for person in persons:\n",
    "    print(person, len(inverted_index[person]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый популярный: Росс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "\n",
    "from math import log\n",
    "\n",
    "k1 = 2.0\n",
    "b = 0.75\n",
    "\n",
    "def score_BM25(qf, dl, avgdl, k1, b, N, n) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    score = log((N - n + 0.5) / (n + 0.5)) * (k1 + 1) * qf / (qf + k1 * (1 - b + b * dl / avgdl))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim(lemma, inverted_index, document_length):\n",
    "    \"\"\"\n",
    "    Compute similarity score between word in search query and all document from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    doc_list = inverted_index[lemma]\n",
    "    relevance_score = {}\n",
    "    avgdl = sum(document_length) / len(document_length)\n",
    "    N = len(document_length)\n",
    "    \n",
    "    for doc in range(N):    \n",
    "        qf = Counter(inverted_index[lemma])[doc]\n",
    "        relevance_score[doc] = score_BM25(qf, document_length[doc], avgdl,\n",
    "                                          2.0, 0.75, N, len(set(inverted_index[lemma])))\n",
    "    return relevance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_result(query, inverted_index, document_length, num_res):\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    Collect as pair (doc_id, score)\n",
    "    :param query: input text\n",
    "    :return: list of lists with (doc_id, score)\n",
    "    \"\"\"\n",
    "    relevance_dict = defaultdict(float)\n",
    "    lemmas, _ = preprocess_words(query)\n",
    "    \n",
    "    for lemma in lemmas:\n",
    "        score = compute_sim(lemma, inverted_index, document_length)\n",
    "        for elem in score:\n",
    "            relevance_dict[elem] += score[elem]\n",
    "            \n",
    "    result = sorted(relevance_dict, key=relevance_dict.get, reverse=True)[:num_res]\n",
    "    \n",
    "    return [(files_list[ind].split('/Friends/Friends - ')[1], relevance_dict[ind]) for ind in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season 7/Friends - 7x10 - The One With The Holiday Armadillo.ru.txt: 9.976228146378661\n",
      "season 6/Friends - 6x19 - The One With Joey's Fridge.ru.txt: 7.917781782429753\n",
      "season 3/Friends - 3x10 - The One Where Rachel Quits.ru.txt: 5.712885994666163\n",
      "season 2/Friends - 2x09 - The One With Phoebe's Dad.ru.txt: 4.849771642565855\n",
      "season 1/Friends - 1x17 - The One With Two Parts (2).ru.txt: 4.107940734356043\n",
      "season 4/Friends - 4x03 - The One With The 'Cuffs.ru.txt: 4.07543546317729\n",
      "season 1/Friends - 1x16 - The One With Two Parts (1).ru.txt: 4.051197790928666\n",
      "season 4/Friends - 4x10 - The One With The Girl From Poughkeepsie.ru.txt: 3.974191647399251\n",
      "season 6/Friends - 6x12 - The One With The Joke.ru.txt: 3.442200369543739\n",
      "season 6/Friends - 6x09 - The One Where Ross Got High.ru.txt: 3.380802007282508\n"
     ]
    }
   ],
   "source": [
    "res = get_search_result('рождественские каникулы', inverted_index, document_length, 10)\n",
    "for elem in res:\n",
    "    print('{}: {}'.format(elem[0], elem[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
